import os
import json
import xml.etree.ElementTree as ET
import streamlit as st
import pandas as pd
import faiss
import numpy as np
import requests
from langchain.llms import AzureOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY = "<your-azure-api-key>"
AZURE_OPENAI_ENDPOINT = "<your-endpoint-url>"
AZURE_OPENAI_DEPLOYMENT_NAME = "<your-deployment-name>"
AZURE_OPENAI_EMBEDDING_DEPLOYMENT = "<your-embedding-deployment-name>"

os.environ["AZURE_OPENAI_API_KEY"] = AZURE_OPENAI_API_KEY
os.environ["AZURE_OPENAI_ENDPOINT"] = AZURE_OPENAI_ENDPOINT
os.environ["AZURE_OPENAI_DEPLOYMENT_NAME"] = AZURE_OPENAI_DEPLOYMENT_NAME

# --- Helper Functions ---

def parse_xml_to_flat_dict(xml_str):
    root = ET.fromstring(xml_str)
    flat_dict = {}
    for field in root.findall(".//field"):
        name = field.find("name").text
        value = field.find("value").text if field.find("value") is not None else ""
        operator = field.find("operator").text if field.find("operator") is not None else ""
        key = name if operator == '' else f"{name}_{operator}"
        flat_dict[key] = value
    return flat_dict

@st.cache_resource
def generate_embeddings(xml_list):
    flat_texts = [json.dumps(parse_xml_to_flat_dict(xml)) for xml in xml_list]
    embeddings = [get_embedding(t) for t in flat_texts]
    dimension = len(embeddings[0])
    index = faiss.IndexFlatL2(dimension)
    index.add(np.array(embeddings).astype('float32'))
    return flat_texts, index

# --- Manual Embedding Call Function ---

def get_embedding(text):
    url = f"{AZURE_OPENAI_ENDPOINT}/openai/deployments/{AZURE_OPENAI_EMBEDDING_DEPLOYMENT}/embeddings?api-version=2023-05-15"
    headers = {
        "Content-Type": "application/json",
        "api-key": AZURE_OPENAI_API_KEY
    }
    data = {
        "input": text
    }
    response = requests.post(url, headers=headers, json=data)
    if response.status_code != 200:
        st.error(f"Embedding API call failed: {response.text}")
        st.stop()
    result = response.json()
    return result["data"][0]["embedding"]

# --- Build LLM and Prompt ---

llm = AzureOpenAI(
    deployment_name=AZURE_OPENAI_DEPLOYMENT_NAME,
    openai_api_key=AZURE_OPENAI_API_KEY,
    openai_api_base=AZURE_OPENAI_ENDPOINT,
    openai_api_version="2023-05-15"
)

prompt_template = PromptTemplate(
    input_variables=["query"],
    template="""
You are a smart data parser. Convert the following user request into structured search terms:

Query: {query}

Return a JSON object ONLY.
"""
)

interpret_chain = LLMChain(
    llm=llm,
    prompt=prompt_template,
    output_key="structured_query"
)

# --- Streamlit Interface ---

st.title("üîç XML ConditionSet Matcher with LangChain + FAISS + Azure OpenAI (NO AzureOpenAIEmbeddings)")
st.markdown("""
Upload a CSV file containing XML strings under a column named `xml`.
The app will match your natural language query to the closest condition sets.
""")

uploaded_file = st.file_uploader("Upload your CSV", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    xml_strings = df['xml'].tolist()
    flat_texts, index = generate_embeddings(xml_strings)

    user_query = st.text_input("Enter your search prompt:", 
        "Find XMLs where product type is DM or DS, currency is USD, and cps between 0.2 and 0.3")

    if st.button("Search"):
        with st.spinner("Running..."):
            # Step 1: Interpret the Query
            output = interpret_chain.run(query=user_query)
            
            try:
                structured_dict = json.loads(output)
            except json.JSONDecodeError:
                st.error("Failed to parse model output as JSON. Try rephrasing your query.")
                st.stop()

            # Step 2: Embed the structured query
            query_text = json.dumps(structured_dict)
            query_embedding = get_embedding(query_text)

            # Step 3: Search FAISS
            D, I = index.search(np.array([query_embedding]).astype('float32'), k=5)
            matches = [flat_texts[i] for i in I[0]]

            # Step 4: Show Results
            st.subheader("üîé Matched Results")
            if matches:
                for m in matches:
                    st.json(json.loads(m))
            else:
                st.warning("No matching results found.")
else:
    st.info("Please upload a CSV to start.")
