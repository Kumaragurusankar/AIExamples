import faiss
import numpy as np
import os
import json
import threading

class FaissVectorStore:
    def __init__(self, dimension: int, index_path: str, nlist: int = 100):
        self.dimension = dimension
        self.index_path = index_path
        self.lock = threading.Lock()
        self.metadata_path = index_path + ".meta.json"
        self.metadata_store = {}
        self.current_id = 0

        if os.path.exists(index_path):
            self.index = faiss.read_index(index_path)
            if os.path.exists(self.metadata_path):
                with open(self.metadata_path, "r") as f:
                    self.metadata_store = json.load(f)
                self.current_id = max(map(int, self.metadata_store.keys()), default=-1) + 1
        else:
            quantizer = faiss.IndexFlatL2(dimension)
            self.index = faiss.IndexIVFFlat(quantizer, dimension, nlist)
            self.index.nprobe = 10  # search parameter
            # Delay training until real data is available

    def train(self, vectors):
        with self.lock:
            if not self.index.is_trained:
                print("Training FAISS index with real embeddings...")
                self.index.train(np.array(vectors).astype('float32'))
                print("Training complete.")
                self.save()

    def add(self, vectors, metadata):
        with self.lock:
            if not self.index.is_trained:
                raise RuntimeError("Index must be trained before adding vectors.")
            vecs = np.array(vectors).astype('float32')
            ids = list(range(self.current_id, self.current_id + len(vectors)))
            self.index.add_with_ids(vecs, np.array(ids))
            for i, meta in zip(ids, metadata):
                self.metadata_store[str(i)] = meta
            self.current_id += len(vectors)
            self.save()

    def save(self):
        faiss.write_index(self.index, self.index_path)
        with open(self.metadata_path, "w") as f:
            json.dump(self.metadata_store, f)

    def search(self, vector, k=5):
        with self.lock:
            if self.index.ntotal == 0:
                return []
            D, I = self.index.search(np.array([vector]).astype('float32'), k)
            return [self.metadata_store[str(i)] for i in I[0] if str(i) in self.metadata_store]



Training FAISS index with real embeddings..


def train(self, vectors):
    with self.lock:
        vecs = np.array(vectors).astype('float32')

        # Validate training input
        if vecs.ndim != 2 or vecs.shape[1] != self.dimension:
            raise ValueError(f"Training data must be shape (n, {self.dimension}), got {vecs.shape}")

        if vecs.shape[0] < self.index.nlist:
            raise ValueError(
                f"FAISS requires at least as many training vectors as nlist ({self.index.nlist}), "
                f"but got only {vecs.shape[0]}"
            )

        print("Training FAISS index with real embeddings...")
        self.index.train(vecs)

        if not self.index.is_trained:
            raise RuntimeError("FAISS training failed: index is still untrained after calling train()")

        print("Training complete.")
        self.save()

def train(self, vectors):
    with self.lock:
        vecs = np.array(vectors).astype('float32')

        # Ensure it's 2D: (n_samples, dimension)
        if vecs.ndim == 1:
            vecs = vecs.reshape(1, -1)

        if vecs.shape[1] != self.dimension:
            raise ValueError(f"Expected dimension {self.dimension}, got {vecs.shape[1]}")

        if vecs.shape[0] < self.index.nlist:
            raise ValueError(
                f"Need at least {self.index.nlist} training vectors, got {vecs.shape[0]}"
            )

        print("Training FAISS index with real embeddings...")
        self.index.train(vecs)

        if not self.index.is_trained:
            raise RuntimeError("FAISS training failed: index is still untrained after calling train()")

        print("Training complete.")
        self.save()
